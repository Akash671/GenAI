{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# upload the training_data.jsonl file to this colab file\n",
        "# upload the validation_data.jsonl file to this colab file\n",
        "# you should have atleast 10 lines in the each of the\n",
        "# jsonl data files"
      ],
      "metadata": {
        "id": "tOJRDEbZFqQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK10FOAd5sJY",
        "outputId": "28125689-0322-4e9e-97b8-acc4b445c8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezCnNacb5k9U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=''\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "training_file_name = \"training_data.jsonl\"\n",
        "validation_file_name = \"validation_data.jsonl\""
      ],
      "metadata": {
        "id": "TuL1z_f3Ao7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do not run this cell, as we are directly giving the\n",
        "# jsonl data files\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "    with open(final_file_name, 'w') as outfile:\n",
        "        for entry in dictionary_data:\n",
        "        \tjson.dump(entry, outfile)\n",
        "        \toutfile.write('\\n')\n",
        "\n",
        "prepare_data(\"/content/sample_data/training_data\", \"training_data.jsonl\")\n",
        "prepare_data(\"/content/sample_data/validation_data\", \"validation_data.jsonl\")"
      ],
      "metadata": {
        "id": "Y5oeC-r0KzW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id = client.files.create(\n",
        "  file=open(\"/content/sample_data/training_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "validation_file_id = client.files.create(\n",
        "  file=open(\"/content/sample_data/validation_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(f\"Training File ID: {training_file_id}\")\n",
        "print(f\"Validation File ID: {validation_file_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXfbZoTAJS-i",
        "outputId": "445871ae-6746-467b-c9f4-f98aa62e25ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training File ID: FileObject(id='file-NRe9TduqUAmuddhqwKdtVoOT', bytes=1575, created_at=1714826716, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
            "Validation File ID: FileObject(id='file-k1DzuO0y2HXcHtSIHWE0BKrB', bytes=1220, created_at=1714826717, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file=training_file_id.id,\n",
        "  validation_file=validation_file_id.id,\n",
        "  model=\"davinci-002\",\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 15,\n",
        "\t\"batch_size\": 3,\n",
        "\t\"learning_rate_multiplier\": 0.3\n",
        "  }\n",
        ")\n",
        "job_id = response.id\n",
        "status = response.status\n",
        "\n",
        "print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {response}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgQssKMWJX6U",
        "outputId": "e8c6f323-7cb0-44ba-8e55-908bff7002b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tunning model with jobID: ftjob-I2dFG1UOjau0h0LVytVJKytb.\n",
            "Training Response: FineTuningJob(id='ftjob-I2dFG1UOjau0h0LVytVJKytb', created_at=1714826724, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='davinci-002', object='fine_tuning.job', organization_id='org-xHcrqMk2YaYXl8DbAVu8rzea', result_files=[], seed=742197130, status='validating_files', trained_tokens=None, training_file='file-NRe9TduqUAmuddhqwKdtVoOT', validation_file='file-k1DzuO0y2HXcHtSIHWE0BKrB', estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Training Status: validating_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import signal\n",
        "import datetime\n",
        "\n",
        "\n",
        "def signal_handler(sig, frame):\n",
        "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
        "    print(f\"Stream interrupted. Job is still {status}.\")\n",
        "    return\n",
        "\n",
        "\n",
        "print(f\"Streaming events for the fine-tuning job: {job_id}\")\n",
        "\n",
        "signal.signal(signal.SIGINT, signal_handler)\n",
        "\n",
        "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
        "try:\n",
        "    for event in events:\n",
        "        print(\n",
        "            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n",
        "        )\n",
        "except Exception:\n",
        "    print(\"Stream interrupted (client disconnected).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmTyyQvJfH0",
        "outputId": "9ac22859-5b39-467e-aa84-3d6e70917e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming events for the fine-tuning job: ftjob-I2dFG1UOjau0h0LVytVJKytb\n",
            "2024-05-04 12:45:24 Validating training file: file-NRe9TduqUAmuddhqwKdtVoOT and validation file: file-k1DzuO0y2HXcHtSIHWE0BKrB\n",
            "2024-05-04 12:45:24 Created fine-tuning job: ftjob-I2dFG1UOjau0h0LVytVJKytb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "status = client.fine_tuning.jobs.retrieve(job_id).status\n",
        "if status not in [\"succeeded\", \"failed\"]:\n",
        "    print(f\"Job not in terminal status: {status}. Waiting.\")\n",
        "    while status not in [\"succeeded\", \"failed\"]:\n",
        "        time.sleep(2)\n",
        "        status = client.fine_tuning.jobs.retrieve(job_id).status\n",
        "        print(f\"Status: {status}\")\n",
        "else:\n",
        "    print(f\"Finetune job {job_id} finished with status: {status}\")\n",
        "print(\"Checking other finetune jobs in the subscription.\")\n",
        "result = client.fine_tuning.jobs.list()\n",
        "print(f\"Found {len(result.data)} finetune jobs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WavNhd2IJh01",
        "outputId": "ebd5010b-1d38-4757-ffa4-f2d255a714b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job not in terminal status: validating_files. Waiting.\n",
            "Status: validating_files\n",
            "Status: validating_files\n",
            "Status: queued\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: succeeded\n",
            "Checking other finetune jobs in the subscription.\n",
            "Found 15 finetune jobs.\n"
          ]
        }
      ]
    }
  ]
}