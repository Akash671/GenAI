{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Finding the Term Frequency - TF- word embeddings"
      ],
      "metadata": {
        "id": "McaUCnWwSu9u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAyrjB3TpWyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgTE7JhXpWqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8cD6IOHpWhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"He is Walter\",\n",
        "    \"He is William\",\n",
        "    \"He isn’t Peter or September\"\n",
        "]\n",
        "\n",
        "# Tokenize the corpus\n",
        "def tokenize(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "# Calculate term frequency (TF)\n",
        "def compute_tf(corpus):\n",
        "    tf = []\n",
        "    for document in corpus:\n",
        "        tokens = tokenize(document)\n",
        "        counter = Counter(tokens)\n",
        "        total_terms = len(tokens)\n",
        "        tf_doc = {term: count / total_terms for term, count in counter.items()}\n",
        "        tf.append(tf_doc)\n",
        "    print(tf)\n",
        "    return tf\n",
        "\n",
        "# Calculate document frequency (DF)\n",
        "def compute_df(corpus):\n",
        "    df = defaultdict(int)\n",
        "    for document in corpus:\n",
        "        tokens = set(tokenize(document))\n",
        "        for token in tokens:\n",
        "            df[token] += 1\n",
        "    print(df)\n",
        "    return df\n",
        "\n",
        "# Calculate inverse document frequency (IDF)\n",
        "def compute_idf(corpus, df):\n",
        "    idf = {}\n",
        "    N = len(corpus)\n",
        "    for term, count in df.items():\n",
        "        idf[term] = math.log10(N / count)\n",
        "    print(idf)\n",
        "    return idf\n",
        "\n",
        "# Calculate TF-IDF\n",
        "def compute_tf_idf(tf, idf):\n",
        "    tf_idf = []\n",
        "    for tf_doc in tf:\n",
        "        tf_idf_doc = {term: tf_val * idf[term] for term, tf_val in tf_doc.items()}\n",
        "        tf_idf.append(tf_idf_doc)\n",
        "    #print(tf_idf)\n",
        "    return tf_idf\n",
        "\n",
        "# Get vocabulary\n",
        "def get_vocabulary(corpus):\n",
        "    vocab = set()\n",
        "    for document in corpus:\n",
        "        tokens = tokenize(document)\n",
        "        vocab.update(tokens)\n",
        "    return sorted(vocab)\n",
        "\n",
        "# Main function to calculate TF-IDF\n",
        "def main(corpus):\n",
        "    tf = compute_tf(corpus)\n",
        "    df = compute_df(corpus)\n",
        "    idf = compute_idf(corpus, df)\n",
        "    tf_idf = compute_tf_idf(tf, idf)\n",
        "\n",
        "    vocab = get_vocabulary(corpus)\n",
        "    tf_idf_matrix = []\n",
        "\n",
        "    for tf_idf_doc in tf_idf:\n",
        "        row = []\n",
        "        for term in vocab:\n",
        "            row.append(tf_idf_doc.get(term, 0))\n",
        "        tf_idf_matrix.append(row)\n",
        "\n",
        "    return vocab, tf_idf_matrix\n",
        "\n",
        "vocab, tf_idf_matrix = main(corpus)\n",
        "\n",
        "#print(\"Vocabulary:\", vocab)\n",
        "#print(\"TF-IDF Matrix:\")\n",
        "#for row in tf_idf_matrix:\n",
        "#    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdwYac0Yq4wI",
        "outputId": "1b8ba191-fca8-4a7d-dd22-bb796e18df1e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'He': 0.3333333333333333, 'is': 0.3333333333333333, 'Walter': 0.3333333333333333}, {'He': 0.3333333333333333, 'is': 0.3333333333333333, 'William': 0.3333333333333333}, {'He': 0.2, 'isn’t': 0.2, 'Peter': 0.2, 'or': 0.2, 'September': 0.2}]\n",
            "defaultdict(<class 'int'>, {'is': 2, 'Walter': 1, 'He': 3, 'William': 1, 'September': 1, 'Peter': 1, 'or': 1, 'isn’t': 1})\n",
            "{'is': 0.17609125905568124, 'Walter': 0.47712125471966244, 'He': 0.0, 'William': 0.47712125471966244, 'September': 0.47712125471966244, 'Peter': 0.47712125471966244, 'or': 0.47712125471966244, 'isn’t': 0.47712125471966244}\n",
            "TF-IDF Matrix:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnZi02Y2-o4k",
        "outputId": "7269c95f-85f4-407d-eea2-9337cf7a0d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['are' 'can' 'create' 'embeddings' 'example' 'is' 'small' 'tensorflow'\n",
            " 'this' 'to' 'use' 'useful' 'very' 'we' 'word']\n",
            "Term Frequency Matrix:\n",
            " [[0 0 0 0 1 1 1 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0 0 0 0 1 1 0 1]\n",
            " [0 1 1 1 0 0 0 1 0 1 1 0 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"this is a small example\",\n",
        "    \"word embeddings are very useful\",\n",
        "    \"we can use tensorflow to create embeddings\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer with term frequency\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to term frequency vectors\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert the term frequency matrix to an array\n",
        "tf_array = X.toarray()\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary:\", feature_names)\n",
        "print(\"Term Frequency Matrix:\\n\", tf_array)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the IDF word embeddings"
      ],
      "metadata": {
        "id": "aO7L57DlTdal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"this is a small example\",\n",
        "    \"word embeddings are very useful\",\n",
        "    \"we can use tensorflow to create embeddings\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer to get the term-document matrix\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Compute the document frequency for each term\n",
        "df = np.sum(X.toarray() > 0, axis=0)\n",
        "\n",
        "# Compute the inverse document frequency (IDF)\n",
        "N = X.shape[0]\n",
        "idf = np.log((N + 1) / (df + 1)) + 1\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dictionary to map terms to their IDF values\n",
        "idf_dict = dict(zip(feature_names, idf))\n",
        "\n",
        "print(\"Vocabulary and IDF values:\")\n",
        "for term, idf_value in idf_dict.items():\n",
        "    print(f\"{term}: {idf_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yz9xwyIQivV",
        "outputId": "63f6cab6-45c9-4825-deae-d5af0a0e5605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary and IDF values:\n",
            "are: 1.6931\n",
            "can: 1.6931\n",
            "create: 1.6931\n",
            "embeddings: 1.2877\n",
            "example: 1.6931\n",
            "is: 1.6931\n",
            "small: 1.6931\n",
            "tensorflow: 1.6931\n",
            "this: 1.6931\n",
            "to: 1.6931\n",
            "use: 1.6931\n",
            "useful: 1.6931\n",
            "very: 1.6931\n",
            "we: 1.6931\n",
            "word: 1.6931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the Term Frequency Inverse Document Frequency - TF-IDF - word embeddings"
      ],
      "metadata": {
        "id": "Ubc2T7L_Tq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"this is a small example\",\n",
        "    \"word embeddings are very useful\",\n",
        "    \"we can use tensorflow to create embeddings\"\n",
        "]\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to TF-IDF vectors\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Convert the TF-IDF matrix to an array\n",
        "tfidf_array = X.toarray()\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary:\", feature_names)\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijzr2O5WP-0S",
        "outputId": "50e45d6a-5799-4e51-9bb5-d59892c30906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['are' 'can' 'create' 'embeddings' 'example' 'is' 'small' 'tensorflow'\n",
            " 'this' 'to' 'use' 'useful' 'very' 'we' 'word']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.         0.5        0.5\n",
            "  0.5        0.         0.5        0.         0.         0.\n",
            "  0.         0.         0.        ]\n",
            " [0.46735098 0.         0.         0.35543247 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.46735098\n",
            "  0.46735098 0.         0.46735098]\n",
            " [0.         0.38988801 0.38988801 0.29651988 0.         0.\n",
            "  0.         0.38988801 0.         0.38988801 0.38988801 0.\n",
            "  0.         0.38988801 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}