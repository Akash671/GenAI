{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Finding the IDF word embeddings"
      ],
      "metadata": {
        "id": "aO7L57DlTdal"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJdFFZSymR84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"He is Walter\",\n",
        "    \"He is William\",\n",
        "    \"He isn’t Peter or September\"\n",
        "]\n",
        "\n",
        "# Function to tokenize sentences\n",
        "def tokenize(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "# Function to calculate term frequency\n",
        "def compute_tf(corpus):\n",
        "    tf = []\n",
        "    for document in corpus:\n",
        "        tokens = tokenize(document)\n",
        "        tf_doc = defaultdict(float)\n",
        "        total_terms = len(tokens)\n",
        "        for token in tokens:\n",
        "            tf_doc[token] += 1.0 / total_terms\n",
        "        tf.append(tf_doc)\n",
        "    return tf\n",
        "\n",
        "# Calculate term frequency\n",
        "tf = compute_tf(corpus)\n",
        "print(\"Term Frequency:\")\n",
        "print(tf )\n",
        "\n",
        "# Print term frequency for each document\n",
        "for i, tf_doc in enumerate(tf):\n",
        "    print(f\"Term Frequency for document {i + 1}:\")\n",
        "    for term, freq in tf_doc.items():\n",
        "        print(f\"  {term}: {freq:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYMOCd0zjJxg",
        "outputId": "c3b3cc64-7e8f-4969-d738-d6b8c1dbf391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term Frequency:\n",
            "[defaultdict(<class 'float'>, {'He': 0.3333333333333333, 'is': 0.3333333333333333, 'Walter': 0.3333333333333333}), defaultdict(<class 'float'>, {'He': 0.3333333333333333, 'is': 0.3333333333333333, 'William': 0.3333333333333333}), defaultdict(<class 'float'>, {'He': 0.2, 'isn’t': 0.2, 'Peter': 0.2, 'or': 0.2, 'September': 0.2})]\n",
            "Term Frequency for document 1:\n",
            "  He: 0.333\n",
            "  is: 0.333\n",
            "  Walter: 0.333\n",
            "Term Frequency for document 2:\n",
            "  He: 0.333\n",
            "  is: 0.333\n",
            "  William: 0.333\n",
            "Term Frequency for document 3:\n",
            "  He: 0.200\n",
            "  isn’t: 0.200\n",
            "  Peter: 0.200\n",
            "  or: 0.200\n",
            "  September: 0.200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"He is Walter\",\n",
        "    \"He is William\",\n",
        "    \"He isn’t Peter or September\"\n",
        "]\n",
        "\n",
        "# Function to tokenize sentences\n",
        "def tokenize(sentence):\n",
        "    return sentence.split()\n",
        "\n",
        "# Function to calculate document frequency\n",
        "def compute_df(corpus):\n",
        "    df = defaultdict(int)\n",
        "    for document in corpus:\n",
        "        tokens = set(tokenize(document))\n",
        "        for token in tokens:\n",
        "            df[token] += 1\n",
        "    return df\n",
        "\n",
        "# Function to calculate inverse document frequency\n",
        "def compute_idf(corpus, df):\n",
        "    idf = {}\n",
        "    N = len(corpus)\n",
        "    for term, count in df.items():\n",
        "        idf[term] = math.log10(N / count)\n",
        "    return idf\n",
        "\n",
        "# Tokenize the corpus and calculate document frequency\n",
        "df = compute_df(corpus)\n",
        "\n",
        "# Calculate inverse document frequency\n",
        "idf = compute_idf(corpus, df)\n",
        "\n",
        "# Print IDF values\n",
        "for term, value in idf.items():\n",
        "    print(f\"IDF('{term}') = {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l4Jz_lSnIJI",
        "outputId": "5f1cad60-167f-4aae-fe40-639252811b58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDF('He') = 0.0000\n",
            "IDF('Walter') = 0.4771\n",
            "IDF('is') = 0.1761\n",
            "IDF('William') = 0.4771\n",
            "IDF('or') = 0.4771\n",
            "IDF('Peter') = 0.4771\n",
            "IDF('September') = 0.4771\n",
            "IDF('isn’t') = 0.4771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the Term Frequency Inverse Document Frequency - TF-IDF - word embeddings"
      ],
      "metadata": {
        "id": "Ubc2T7L_Tq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Pb_Q0R8oDOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"He is Walter\",\n",
        "    \"He is William\",\n",
        "    \"He isn’t Peter or September\"\n",
        "]\n",
        "\n",
        "# Initialize the CountVectorizer to get the term-document matrix\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Compute the document frequency for each term\n",
        "df = np.sum(X.toarray() > 0, axis=0)\n",
        "\n",
        "# Compute the inverse document frequency (IDF)\n",
        "N = X.shape[0]\n",
        "idf = np.log((N+1) / (df+1)) + 1\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dictionary to map terms to their IDF values\n",
        "idf_dict = dict(zip(feature_names, idf))\n",
        "\n",
        "print(\"Vocabulary and IDF values:\")\n",
        "for term, idf_value in idf_dict.items():\n",
        "    print(f\"{term}: {idf_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc98a2f9-0b53-401d-b9ab-6b8be6816f83",
        "id": "rAUwrc2roD65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary and IDF values:\n",
            "he: 1.0000\n",
            "is: 1.2877\n",
            "isn: 1.6931\n",
            "or: 1.6931\n",
            "peter: 1.6931\n",
            "september: 1.6931\n",
            "walter: 1.6931\n",
            "william: 1.6931\n"
          ]
        }
      ]
    }
  ]
}