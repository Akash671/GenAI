{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxQiCRlhE-Wi"
      },
      "outputs": [],
      "source": [
        "# we train the word2vec model by downloading the text8 corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the text8 corpus\n",
        "dataset = api.load(\"text8\")\n",
        "\n",
        "# Build the Word2Vec model\n",
        "model = Word2Vec(dataset, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the model\n",
        "model.save('text8_word2vec.model')\n",
        "\n",
        "# Load the saved model\n",
        "model = Word2Vec.load('text8_word2vec.model')\n",
        "\n",
        "# Example: Get the vector for a word\n",
        "word = \"king\"\n",
        "if word in model.wv.key_to_index:\n",
        "    vector = model.wv[word]\n",
        "    print(f\"Embedding for the word '{word}':\\n{vector}\")\n",
        "else:\n",
        "    print(f\"The word '{word}' is not in the vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Fl_2yWMADc",
        "outputId": "014ea544-86dd-48ad-f99e-1d754c417f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n",
            "Embedding for the word 'king':\n",
            "[-2.324854    1.0537138   3.5300672  -0.27410188  1.112171    4.034314\n",
            "  0.7149382   1.4151459  -3.6784499   0.47274044  0.5830803  -0.86555445\n",
            "  0.7004507   4.107307   -0.42135254 -1.1044253   1.1117389  -0.98056406\n",
            "  3.155394   -2.2107787  -0.6895847   3.6296952  -1.5270089   2.374229\n",
            "  2.7847693   0.449584    1.3031222   0.9952793  -1.8932054  -1.2520372\n",
            "  0.4231173   0.770195   -1.8840412   2.2435627   2.595141    2.1350915\n",
            "  1.9264061   1.3524189   1.4411801  -1.0919354  -0.5362063   1.2264758\n",
            "  0.24570417 -0.49052998 -1.8595148   1.5203513  -0.42497927 -1.6706431\n",
            "  2.9222326  -2.1031542   3.4698274   1.2972537  -2.845163    3.759958\n",
            " -0.06765749 -0.9252918  -0.4299855   1.1123027   1.1844947  -2.5237405\n",
            "  2.2416208   0.4678127   0.9740288  -0.94552153  1.1336007  -1.4928662\n",
            " -0.37538657  0.75676554  1.1662623  -2.6315148   1.3468332  -0.9357353\n",
            " -1.2409922  -2.510408    2.1008666  -1.4673597   1.368788    0.12870081\n",
            " -3.1238806   0.40992755 -1.0883881  -4.5083766   1.7417073   2.820125\n",
            " -0.92091614  1.0540814   1.9335409  -0.63359535 -0.21943857  2.2670166\n",
            " -2.2197475   2.726509   -0.8567789  -1.0307148   0.4677315  -0.43610972\n",
            "  0.19463594  1.3123329  -0.40305802  0.2130735 ]\n"
          ]
        }
      ]
    }
  ]
}