{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Layer\n",
        "\n",
        "class PositionEmbeddingFixedWeights(Layer):\n",
        "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
        "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
        "        self.word_embedding_layer = Embedding(\n",
        "            input_dim=vocab_size, output_dim=output_dim,\n",
        "            weights=[word_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "        self.position_embedding_layer = Embedding(\n",
        "            input_dim=seq_length, output_dim=output_dim,\n",
        "            weights=[pos_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    def get_position_encoding(self, seq_len, d, n=10000):\n",
        "        P = np.zeros((seq_len, d))\n",
        "        for k in range(seq_len):\n",
        "            for i in np.arange(int(d/2)):\n",
        "                denominator = np.power(n, 2*i/d)\n",
        "                P[k, 2*i] = np.sin(k/denominator)\n",
        "                P[k, 2*i+1] = np.cos(k/denominator)\n",
        "        return P\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
        "        embedded_words = self.word_embedding_layer(inputs)\n",
        "        embedded_indices = self.position_embedding_layer(position_indices)\n",
        "        return embedded_words + embedded_indices\n"
      ],
      "metadata": {
        "id": "qFZohrvoW9en"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
        "from tensorflow.keras.layers import Dense, Layer\n",
        "from tensorflow.keras.backend import softmax\n",
        "\n",
        "# Implementing the Scaled-Dot Product Attention\n",
        "class DotProductAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, queries, keys, values, d_k, mask=None):\n",
        "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
        "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
        "\n",
        "        # Apply mask to the attention scores\n",
        "        if mask is not None:\n",
        "            scores += -1e9 * mask\n",
        "\n",
        "        # Computing the weights by a softmax operation\n",
        "        weights = softmax(scores)\n",
        "\n",
        "        # Computing the attention by a weighted sum of the value vectors\n",
        "        return matmul(weights, values)\n",
        "\n",
        "# Implementing the Multi-Head Attention\n",
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
        "        self.heads = h  # Number of attention heads to use\n",
        "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
        "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
        "        self.d_model = d_model  # Dimensionality of the model\n",
        "        self.W_q = Dense(d_k)   # Learned projection matrix for the queries\n",
        "        self.W_k = Dense(d_k)   # Learned projection matrix for the keys\n",
        "        self.W_v = Dense(d_v)   # Learned projection matrix for the values\n",
        "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
        "\n",
        "    def reshape_tensor(self, x, heads, flag):\n",
        "        if flag:\n",
        "            # Tensor shape after reshaping and transposing:\n",
        "            # (batch_size, heads, seq_length, -1)\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "        else:\n",
        "            # Reverting the reshaping and transposing operations:\n",
        "            # (batch_size, seq_length, d_k)\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
        "        return x\n",
        "\n",
        "    def call(self, queries, keys, values, mask=None):\n",
        "        # Rearrange the queries to be able to compute all heads in parallel\n",
        "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the keys to be able to compute all heads in parallel\n",
        "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the values to be able to compute all heads in parallel\n",
        "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Compute the multi-head attention output using the reshaped queries,\n",
        "        # keys, and values\n",
        "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange back the output into concatenated form\n",
        "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
        "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
        "\n",
        "        # Apply one final linear projection to the output to generate the multi-head\n",
        "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
        "        return self.W_o(output)\n"
      ],
      "metadata": {
        "id": "qDbmobh1XCzz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
        "#from multihead_attention import MultiHeadAttention\n",
        "#from positional_encoding import PositionEmbeddingFixedWeights\n",
        "\n",
        "# Implementing the Add & Norm Layer\n",
        "class AddNormalization(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
        "\n",
        "    def call(self, x, sublayer_x):\n",
        "        # The sublayer input and output need to be of the same shape to be summed\n",
        "        add = x + sublayer_x\n",
        "\n",
        "        # Apply layer normalization to the sum\n",
        "        return self.layer_norm(add)\n",
        "\n",
        "# Implementing the Feed-Forward Layer\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, d_ff, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
        "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
        "        self.activation = ReLU()  # ReLU activation layer\n",
        "\n",
        "    def call(self, x):\n",
        "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
        "        x_fc1 = self.fully_connected1(x)\n",
        "\n",
        "        return self.fully_connected2(self.activation(x_fc1))\n",
        "\n",
        "# Implementing the Encoder Layer\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "\n",
        "    def call(self, x, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output = self.dropout1(multihead_output, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output = self.add_norm1(x, multihead_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm2(addnorm_output, feedforward_output)\n",
        "\n",
        "# Implementing the Encoder\n",
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
        "                       **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
        "                                                          d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
        "                              for _ in range(n)]\n",
        "\n",
        "    def call(self, input_sentence, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.encoder_layer):\n",
        "            x = layer(x, padding_mask, training)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Li-7bUPzWv4s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.layers import Layer, Dropout\n",
        "#from multihead_attention import MultiHeadAttention\n",
        "#from positional_encoding import PositionEmbeddingFixedWeights\n",
        "#from encoder import AddNormalization, FeedForward\n",
        "\n",
        "# Implementing the Decoder Layer\n",
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout3 = Dropout(rate)\n",
        "        self.add_norm3 = AddNormalization()\n",
        "\n",
        "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by another multi-head attention layer\n",
        "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,\n",
        "                                                      encoder_output, padding_mask)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output2)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm3(addnorm_output2, feedforward_output)\n",
        "\n",
        "# Implementing the Decoder\n",
        "class Decoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
        "                       **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
        "                                                          d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
        "                              for _ in range(n)]\n",
        "\n",
        "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(output_target)\n",
        "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.decoder_layer):\n",
        "            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "932mgNOUXMT7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load, dump, HIGHEST_PROTOCOL\n",
        "from numpy.random import shuffle\n",
        "from numpy import savetxt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64\n",
        "\n",
        "class PrepareDataset:\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_sentences = 15000  # Number of sentences to include in the dataset\n",
        "        self.train_split = 0.8  # Ratio of the training data split\n",
        "        self.val_split = 0.1  # Ratio of the validation data split\n",
        "\n",
        "    # Fit a tokenizer\n",
        "    def create_tokenizer(self, dataset):\n",
        "        tokenizer = Tokenizer()\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return tokenizer\n",
        "\n",
        "    def find_seq_length(self, dataset):\n",
        "        return max(len(seq.split()) for seq in dataset)\n",
        "\n",
        "    def find_vocab_size(self, tokenizer, dataset):\n",
        "        tokenizer.fit_on_texts(dataset)\n",
        "\n",
        "        return len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Encode and pad the input sequences\n",
        "    def encode_pad(self, dataset, tokenizer, seq_length):\n",
        "        x = tokenizer.texts_to_sequences(dataset)\n",
        "        x = pad_sequences(x, maxlen=seq_length, padding='post')\n",
        "        x = convert_to_tensor(x, dtype=int64)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_tokenizer(self, tokenizer, name):\n",
        "        with open(name + '_tokenizer.pkl', 'wb') as handle:\n",
        "            dump(tokenizer, handle, protocol=HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __call__(self, filename, **kwargs):\n",
        "        # Load a clean dataset\n",
        "        clean_dataset = load(open(filename, 'rb'))\n",
        "\n",
        "        # Reduce dataset size\n",
        "        dataset = clean_dataset[:self.n_sentences, :]\n",
        "\n",
        "        # Include start and end of string tokens\n",
        "        for i in range(dataset[:, 0].size):\n",
        "            dataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
        "            dataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
        "\n",
        "        # Random shuffle the dataset\n",
        "        shuffle(dataset)\n",
        "\n",
        "        # Split the dataset in training, validation and test sets\n",
        "        train = dataset[:int(self.n_sentences * self.train_split)]\n",
        "        val = dataset[int(self.n_sentences * self.train_split):\n",
        "                      int(self.n_sentences * (1-self.val_split))]\n",
        "        test = dataset[int(self.n_sentences * (1 - self.val_split)):]\n",
        "\n",
        "        # Prepare tokenizer for the encoder input\n",
        "        enc_tokenizer = self.create_tokenizer(dataset[:, 0])\n",
        "        enc_seq_length = self.find_seq_length(dataset[:, 0])\n",
        "        enc_vocab_size = self.find_vocab_size(enc_tokenizer, train[:, 0])\n",
        "\n",
        "        # Prepare tokenizer for the decoder input\n",
        "        dec_tokenizer = self.create_tokenizer(dataset[:, 1])\n",
        "        dec_seq_length = self.find_seq_length(dataset[:, 1])\n",
        "        dec_vocab_size = self.find_vocab_size(dec_tokenizer, train[:, 1])\n",
        "\n",
        "        # Encode and pad the training input\n",
        "        trainX = self.encode_pad(train[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        trainY = self.encode_pad(train[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Encode and pad the validation input\n",
        "        valX = self.encode_pad(val[:, 0], enc_tokenizer, enc_seq_length)\n",
        "        valY = self.encode_pad(val[:, 1], dec_tokenizer, dec_seq_length)\n",
        "\n",
        "        # Save the encoder tokenizer\n",
        "        self.save_tokenizer(enc_tokenizer, 'enc')\n",
        "\n",
        "        # Save the decoder tokenizer\n",
        "        self.save_tokenizer(dec_tokenizer, 'dec')\n",
        "\n",
        "        # Save the testing dataset into a text file\n",
        "        savetxt('test_dataset.txt', test, fmt='%s')\n",
        "\n",
        "        return (trainX, trainY, valX, valY, train, val, enc_seq_length,\n",
        "                dec_seq_length, enc_vocab_size, dec_vocab_size)\n"
      ],
      "metadata": {
        "id": "9micACWqXMNc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from encoder import Encoder\n",
        "#from decoder import Decoder\n",
        "from tensorflow import math, cast, float32, linalg, ones, maximum, newaxis\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class TransformerModel(Model):\n",
        "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length,\n",
        "                       h, d_k, d_v, d_model, d_ff_inner, n, rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Set up the encoder\n",
        "        self.encoder = Encoder(enc_vocab_size, enc_seq_length, h, d_k, d_v,\n",
        "                               d_model, d_ff_inner, n, rate)\n",
        "\n",
        "        # Set up the decoder\n",
        "        self.decoder = Decoder(dec_vocab_size, dec_seq_length, h, d_k, d_v,\n",
        "                               d_model, d_ff_inner, n, rate)\n",
        "\n",
        "        # Define the final dense layer\n",
        "        self.model_last_layer = Dense(dec_vocab_size)\n",
        "\n",
        "    def padding_mask(self, input):\n",
        "        # Create mask which marks the zero padding values in the input by a 1.0\n",
        "        mask = math.equal(input, 0)\n",
        "        mask = cast(mask, float32)\n",
        "\n",
        "        # The shape of the mask should be broadcastable to the shape\n",
        "        # of the attention weights that it will be masking later on\n",
        "        return mask[:, newaxis, newaxis, :]\n",
        "\n",
        "    def lookahead_mask(self, shape):\n",
        "        # Mask out future entries by marking them with a 1.0\n",
        "        mask = 1 - linalg.band_part(ones((shape, shape)), -1, 0)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def call(self, encoder_input, decoder_input, training):\n",
        "\n",
        "        # Create padding mask to mask the encoder inputs and the encoder\n",
        "        # outputs in the decoder\n",
        "        enc_padding_mask = self.padding_mask(encoder_input)\n",
        "\n",
        "        # Create and combine padding and look-ahead masks to be fed into the decoder\n",
        "        dec_in_padding_mask = self.padding_mask(decoder_input)\n",
        "        dec_in_lookahead_mask = self.lookahead_mask(decoder_input.shape[1])\n",
        "        dec_in_lookahead_mask = maximum(dec_in_padding_mask, dec_in_lookahead_mask)\n",
        "\n",
        "        # Feed the input into the encoder\n",
        "        encoder_output = self.encoder(encoder_input, enc_padding_mask, training)\n",
        "\n",
        "        # Feed the encoder output into the decoder\n",
        "        decoder_output = self.decoder(decoder_input, encoder_output,\n",
        "                                      dec_in_lookahead_mask, enc_padding_mask, training)\n",
        "\n",
        "        # Pass the decoder output through a final dense layer\n",
        "        model_output = self.model_last_layer(decoder_output)\n",
        "\n",
        "        return model_output\n"
      ],
      "metadata": {
        "id": "CoU-brzxXiwN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from tensorflow import Module\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64, TensorArray, argmax, newaxis, transpose\n",
        "#from model import TransformerModel\n",
        "\n",
        "# Define the model parameters\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_model = 512  # Dimensionality of model layers' outputs\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "# Define the dataset parameters\n",
        "enc_seq_length = 7  # Encoder sequence length\n",
        "dec_seq_length = 12  # Decoder sequence length\n",
        "enc_vocab_size = 2404  # Encoder vocabulary size\n",
        "dec_vocab_size = 3864  # Decoder vocabulary size\n",
        "\n",
        "# Create model\n",
        "inferencing_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
        "                                     dec_seq_length, h, d_k, d_v, d_model, d_ff, n, 0)\n",
        "\n",
        "class Translate(Module):\n",
        "    def __init__(self, inferencing_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.transformer = inferencing_model\n",
        "\n",
        "    def load_tokenizer(self, name):\n",
        "        with open(name, 'rb') as handle:\n",
        "            return load(handle)\n",
        "\n",
        "    def __call__(self, sentence):\n",
        "        # Append start and end of string tokens to the input sentence\n",
        "        sentence[0] = \"<START> \" + sentence[0] + \" <EOS>\"\n",
        "\n",
        "        # Load encoder and decoder tokenizers\n",
        "        enc_tokenizer = self.load_tokenizer('enc_tokenizer.pkl')\n",
        "        dec_tokenizer = self.load_tokenizer('dec_tokenizer.pkl')\n",
        "\n",
        "        # Prepare the input sentence by tokenizing, padding and converting to tensor\n",
        "        encoder_input = enc_tokenizer.texts_to_sequences(sentence)\n",
        "        encoder_input = pad_sequences(encoder_input,\n",
        "                                      maxlen=enc_seq_length, padding='post')\n",
        "        encoder_input = convert_to_tensor(encoder_input, dtype=int64)\n",
        "\n",
        "        # Prepare the output <START> token by tokenizing, and converting to tensor\n",
        "        output_start = dec_tokenizer.texts_to_sequences([\"<START>\"])\n",
        "        output_start = convert_to_tensor(output_start[0], dtype=int64)\n",
        "\n",
        "        # Prepare the output <EOS> token by tokenizing, and converting to tensor\n",
        "        output_end = dec_tokenizer.texts_to_sequences([\"<EOS>\"])\n",
        "        output_end = convert_to_tensor(output_end[0], dtype=int64)\n",
        "\n",
        "        # Prepare the output array of dynamic size\n",
        "        decoder_output = TensorArray(dtype=int64, size=0, dynamic_size=True)\n",
        "        decoder_output = decoder_output.write(0, output_start)\n",
        "\n",
        "        for i in range(dec_seq_length):\n",
        "            # Predict an output token\n",
        "            prediction = self.transformer(encoder_input,transpose(decoder_output.stack()),\n",
        "                                          training=False)\n",
        "            prediction = prediction[:, -1, :]\n",
        "\n",
        "            # Select the prediction with the highest score\n",
        "            predicted_id = argmax(prediction, axis=-1)\n",
        "            predicted_id = predicted_id[0][newaxis]\n",
        "\n",
        "            # Write the selected prediction to the output array at the next\n",
        "            # available index\n",
        "            decoder_output = decoder_output.write(i + 1, predicted_id)\n",
        "\n",
        "            # Break if an <EOS> token is predicted\n",
        "            if predicted_id == output_end:\n",
        "                break\n",
        "\n",
        "        output = transpose(decoder_output.stack())[0]\n",
        "        output = output.numpy()\n",
        "\n",
        "        output_str = []\n",
        "\n",
        "        # Decode the predicted tokens into an output string\n",
        "        for i in range(output.shape[0]):\n",
        "            key = output[i]\n",
        "            output_str.append(dec_tokenizer.index_word[key])\n",
        "\n",
        "        return output_str\n"
      ],
      "metadata": {
        "id": "HTXgoaFKXzNn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "from tensorflow import Module\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import convert_to_tensor, int64, TensorArray, argmax, newaxis, transpose\n",
        "#from model import TransformerModel\n",
        "\n",
        "# Define the model parameters\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_model = 512  # Dimensionality of model layers' outputs\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "# Define the dataset parameters\n",
        "enc_seq_length = 7  # Encoder sequence length\n",
        "dec_seq_length = 12  # Decoder sequence length\n",
        "enc_vocab_size = 2404  # Encoder vocabulary size\n",
        "dec_vocab_size = 3864  # Decoder vocabulary size\n",
        "\n",
        "# Create model\n",
        "inferencing_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
        "                                     dec_seq_length, h, d_k, d_v, d_model, d_ff, n, 0)\n",
        "\n",
        "class Translate(Module):\n",
        "    def __init__(self, inferencing_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.transformer = inferencing_model\n",
        "\n",
        "    def load_tokenizer(self, name):\n",
        "        with open(name, 'rb') as handle:\n",
        "            return load(handle)\n",
        "\n",
        "    def __call__(self, sentence):\n",
        "        # Append start and end of string tokens to the input sentence\n",
        "        sentence[0] = \"<START> \" + sentence[0] + \" <EOS>\"\n",
        "\n",
        "        # Load encoder and decoder tokenizers\n",
        "        enc_tokenizer = self.load_tokenizer('enc_tokenizer.pkl')\n",
        "        dec_tokenizer = self.load_tokenizer('dec_tokenizer.pkl')\n",
        "\n",
        "        # Prepare the input sentence by tokenizing, padding and converting to tensor\n",
        "        encoder_input = enc_tokenizer.texts_to_sequences(sentence)\n",
        "        encoder_input = pad_sequences(encoder_input,\n",
        "                                      maxlen=enc_seq_length, padding='post')\n",
        "        encoder_input = convert_to_tensor(encoder_input, dtype=int64)\n",
        "\n",
        "        # Prepare the output <START> token by tokenizing, and converting to tensor\n",
        "        output_start = dec_tokenizer.texts_to_sequences([\"<START>\"])\n",
        "        output_start = convert_to_tensor(output_start[0], dtype=int64)\n",
        "\n",
        "        # Prepare the output <EOS> token by tokenizing, and converting to tensor\n",
        "        output_end = dec_tokenizer.texts_to_sequences([\"<EOS>\"])\n",
        "        output_end = convert_to_tensor(output_end[0], dtype=int64)\n",
        "\n",
        "        # Prepare the output array of dynamic size\n",
        "        decoder_output = TensorArray(dtype=int64, size=0, dynamic_size=True)\n",
        "        decoder_output = decoder_output.write(0, output_start)\n",
        "\n",
        "        for i in range(dec_seq_length):\n",
        "            # Predict an output token\n",
        "            prediction = self.transformer(encoder_input,transpose(decoder_output.stack()),\n",
        "                                          training=False)\n",
        "            prediction = prediction[:, -1, :]\n",
        "\n",
        "            # Select the prediction with the highest score\n",
        "            predicted_id = argmax(prediction, axis=-1)\n",
        "            predicted_id = predicted_id[0][newaxis]\n",
        "\n",
        "            # Write the selected prediction to the output array at the next\n",
        "            # available index\n",
        "            decoder_output = decoder_output.write(i + 1, predicted_id)\n",
        "\n",
        "            # Break if an <EOS> token is predicted\n",
        "            if predicted_id == output_end:\n",
        "                break\n",
        "\n",
        "        output = transpose(decoder_output.stack())[0]\n",
        "        output = output.numpy()\n",
        "\n",
        "        output_str = []\n",
        "\n",
        "        # Decode the predicted tokens into an output string\n",
        "        for i in range(output.shape[0]):\n",
        "            key = output[i]\n",
        "            output_str.append(dec_tokenizer.index_word[key])\n",
        "\n",
        "        return output_str\n",
        "\n"
      ],
      "metadata": {
        "id": "Tcd0oBebYCrN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am getting an error while doing inference. The program works fine till this point"
      ],
      "metadata": {
        "id": "w7R6S9OpsPbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence to translate\n",
        "sentence = ['im thirsty']\n",
        "\n",
        "# Load the trained model's weights at the specified epoch\n",
        "inferencing_model.load_weights('weights/wghts16.ckpt')\n",
        "\n",
        "# Create a new instance of the 'Translate' class\n",
        "translator = Translate(inferencing_model)\n",
        "\n",
        "# Translate the input sentence\n",
        "print(translator(sentence))\n"
      ],
      "metadata": {
        "id": "VC1VrJwOZz3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}