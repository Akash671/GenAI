{

  "cells": [

    {

      "cell_type": "markdown",

      "metadata": {

        "id": "Q89r_iogjCsp"

      },

      "source": [

        "# Introduction to word embeddings and distributed representation of words\n",

        "\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "##Popular word embedding models: Word2Vec and GloVe\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "##Hands-on exercise: Training Word2Vec model and exploring pre-trained embeddings"

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "https://www.youtube.com/watch?v=hQwFeIupNP0\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "https://towardsdatascience.com/skip-gram-neural-network-from-scratch-485f2e688238\n",

        "\n",

        "---\n",

        "\n",

        "https://medium.com/swlh/differences-between-word2vec-and-bert-c08a3326b5d1\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "\n",

        "https://www.nltk.org/howto/gensim.html"

      ],

      "metadata": {

        "id": "fzqxIAQtuzKj"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "import numpy as np\n",

        "\n",

        "# vector representing the word 'beer'\n",

        "vec1_beer = np.array([0.9, 0.82, 0.75])\n",

        "\n",

        "# vector representing the word 'wine'\n",

        "vec2_wine = np.array([0.5, 0.98, 0.92])\n",

        "\n",

        "# vector representing the word 'house'\n",

        "vec3_house = np.array([0.91, 0.11, 0.25])\n",

        "\n",

        "\n",

        "def cosine_similarity(w1, w2):\n",

        "  return np.dot(w1,w2)/(np.dot(w1,w1)*np.dot(w2,w2))**0.5\n",

        "\n",

        "print('Similarity between beer & wine:   ', cosine_similarity(vec1_beer,vec2_wine)) # -> output: 0.947\n",

        "print('Similarity between beer & house: ', cosine_similarity(vec1_beer,vec3_house)) # -> output: 0.807\n",

        "print('Similarity between wine & house:    ', cosine_similarity(vec2_winr, vec3_house)) # -> output: 0.581\n"

      ],

      "metadata": {

        "id": "YUq0RcOYxtHP"

      },

      "execution_count": null,

      "outputs": []

    },

    {

      "cell_type": "markdown",

      "source": [

        "# Training word2vec"

      ],

      "metadata": {

        "id": "Uhrrw5w3zt3P"

      }

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "id": "tR_l-gETtmSt"

      },

      "outputs": [],

      "source": [

        "# Import necessary libraries\n",

        "import nltk\n",

        "from nltk.corpus import brown\n",

        "from gensim.models import Word2Vec"

      ]

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "UPutVwyylie_",

        "outputId": "22f87e5a-bc4f-435f-c397-9d48b199acab"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",

            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"

          ]

        },

        {

          "output_type": "execute_result",

          "data": {

            "text/plain": [

              "True"

            ]

          },

          "metadata": {},

          "execution_count": 3

        }

      ],

      "source": [

        "nltk.download('punkt')"

      ]

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "wTJPKjsakSFN",

        "outputId": "8fefc6d4-fac6-4524-8fe0-fa05464d2bd6"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "[nltk_data] Downloading package brown to /root/nltk_data...\n",

            "[nltk_data]   Unzipping corpora/brown.zip.\n"

          ]

        }

      ],

      "source": [

        "# Download the Brown corpus from NLTK\n",

        "nltk.download('brown')\n",

        "\n",

        "# Load the Brown corpus\n",

        "corpus = brown.sents()"

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "#Word2Vec class is instantiated with the specified parameters:\n",

        "\n",

        "corpus: It represents the input text corpus, which is assumed to be assigned to the variable corpus.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "vector_size: It determines the dimensionality of the word vectors, set to 100 in this case.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "window: It defines the window size for the context words, set to 5.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "min_count: It specifies the minimum frequency threshold for words to be included in the vocabulary, set to 5.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "workers: It determines the number of worker threads used for training the model in parallel, set to 4."

      ],

      "metadata": {

        "id": "UQROSy7B2gFu"

      }

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "M3Rn7nWvkSWE",

        "outputId": "0f8e0f08-0a6e-4fbe-bbeb-334272b46248"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Similar words to 'house': [('car', 0.9466149806976318), ('room', 0.9146735668182373), ('hand', 0.8710554838180542), ('bed', 0.8634669780731201), ('door', 0.8606128096580505), ('hall', 0.8588022589683533), ('office', 0.8505901098251343), ('hands', 0.8488484621047974), ('face', 0.8458495736122131), ('close', 0.8431581854820251)]\n"

          ]

        }

      ],

      "source": [

        "# Train Word2Vec model on the Brown corpus\n",

        "model = Word2Vec(corpus, vector_size=100, window=5, min_count=5, workers=4)\n",

        "# Test the trained Word2Vec model\n",

        "similar_words = model.wv.most_similar('house')\n",

        "print(\"Similar words to 'house':\", similar_words)"

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "# Exercise 1: Train Word2Vec model on a different corpus"

      ],

      "metadata": {

        "id": "gJLkHvOEz_ET"

      }

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "Fau7DL_VkSkP",

        "outputId": "d5f5433e-ace4-4b27-e37c-352a332ca983"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",

            "[nltk_data]   Package gutenberg is already up-to-date!\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Similar words to 'love': [('awful', 0.8148207664489746), ('exquisite', 0.8071579337120056), ('singular', 0.8032702207565308), ('remarkable', 0.8004785180091858), ('active', 0.7999264001846313), ('improper', 0.7980139255523682), ('uncommon', 0.7917614579200745), ('ingenious', 0.7865627408027649), ('artist', 0.784122884273529), ('admirable', 0.77900630235672)]\n"

          ]

        }

      ],

      "source": [

        "\n",

        "# 1.1 Download a different corpus using NLTK (e.g., Gutenberg Corpus)\n",

        "nltk.download('gutenberg')\n",

        "\n",

        "# 1.2 Preprocess the corpus (e.g., tokenization, lowercasing)\n",

        "gutenberg_corpus = nltk.corpus.gutenberg.sents()\n",

        "preprocessed_corpus = [[token.lower() for token in sentence] for sentence in gutenberg_corpus]\n",

        "\n",

        "# 1.3 Train a Word2Vec model on the preprocessed corpus\n",

        "new_model = Word2Vec(preprocessed_corpus, vector_size=100, window=5, min_count=5, workers=4)\n",

        "\n",

        "# 1.4 Test the trained Word2Vec model with different words\n",

        "similar_words = new_model.wv.most_similar('extraordinary')\n",

        "print(\"Similar words to 'love':\", similar_words)"

      ]

    },

    {

      "cell_type": "markdown",

      "source": [],

      "metadata": {

        "id": "xR8uQYD5YmIJ"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "# Exercise 2: Explore other pre-trained Word2Vec embeddings"

      ],

      "metadata": {

        "id": "eK88SoFuz2JG"

      }

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "YZUmqmjokSxj",

        "outputId": "4bee9008-adfe-41e2-9e6b-53e29c1337c7"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "--2023-06-07 10:27:28--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",

            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",

            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",

            "HTTP request sent, awaiting response... 301 Moved Permanently\n",

            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",

            "--2023-06-07 10:27:28--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",

            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",

            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",

            "HTTP request sent, awaiting response... 200 OK\n",

            "Length: 2176768927 (2.0G) [application/zip]\n",

            "Saving to: â€˜glove.840B.300d.zipâ€™\n",

            "\n",

            "glove.840B.300d.zip 100%[===================>]   2.03G  4.98MB/s    in 6m 50s  \n",

            "\n",

            "2023-06-07 10:34:19 (5.06 MB/s) - â€˜glove.840B.300d.zipâ€™ saved [2176768927/2176768927]\n",

            "\n",

            "Archive:  glove.840B.300d.zip\n",

            "  inflating: glove.840B.300d.txt     \n"

          ]

        }

      ],

      "source": [

        "\n",

        "# 2.1 Find and download other pre-trained Word2Vec models\n",

        "# - You can explore other pre-trained models from websites like GloVe, FastText, etc.\n",

        "\n",

        "# 2.2 Load the pre-trained model using `KeyedVectors.load_word2vec_format()`\n",

        "from gensim.models import KeyedVectors\n",

        "\n",

        "# Download pre-trained Word2Vec embeddings (GloVe)\n",

        "# Note: This file is large (about 1.4GB) and may take some time to download.\n",

        "# You can comment out this line if the file is already downloaded.\n",

        "!wget -c \"https://nlp.stanford.edu/data/glove.840B.300d.zip\"\n",

        "!unzip glove.840B.300d.zip"

      ]

    },

    {

      "cell_type": "code",

      "execution_count": null,

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "4iYTuC2sob55",

        "outputId": "14843e7b-c96a-4271-ae4c-cc7a02f6522f"

      },

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "WARNING:gensim.models.keyedvectors:duplicate word 'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½' in word2vec file, ignoring all but first\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Similar words to 'technology': [('technologies', 0.8787461519241333), ('technological', 0.7222408652305603), ('innovation', 0.7079066634178162), ('innovations', 0.6894813776016235), ('innovative', 0.6559900045394897), ('capabilities', 0.6543591022491455), ('high-tech', 0.6419724225997925), ('systems', 0.6346928477287292), ('advancements', 0.6320609450340271), ('Technology', 0.6287643909454346)]\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in true_divide\n",

            "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"

          ]

        }

      ],

      "source": [

        "# 2.2 Load the pre-trained model using `KeyedVectors.load_word2vec_format()`\n",

        "from gensim.models import KeyedVectors\n",

        "\n",

        "# Load pre-trained Word2Vec embeddings\n",

        "pretrained_model = KeyedVectors.load_word2vec_format('glove.840B.300d.txt', binary=False, no_header=True)\n",

        "\n",

        "# 2.3 Test the pre-trained Word2Vec model with different words\n",

        "similar_words = pretrained_model.most_similar('technology')\n",

        "print(\"Similar words to 'technology':\", similar_words)\n"

      ]

    }

  ],

  "metadata": {

    "colab": {

      "provenance": []

    },

    "kernelspec": {

      "display_name": "Python 3",

      "name": "python3"

    },

    "language_info": {

      "name": "python"

    }

  },

  "nbformat": 4,

  "nbformat_minor": 0

}

 

