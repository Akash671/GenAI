{

  "nbformat": 4,

  "nbformat_minor": 0,

  "metadata": {

    "colab": {

      "provenance": []

    },

    "kernelspec": {

      "name": "python3",

      "display_name": "Python 3"

    },

    "language_info": {

      "name": "python"

    }

  },

  "cells": [

    {

      "cell_type": "markdown",

      "source": [

        "Introduction to topic modeling and its applications\n",

        "---\n",

        "Popular topic modeling algorithms: Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF)\n",

        "---\n",

        "Hands-on exercise: Implementing a topic modeling algorithm (e.g., LDA) using\n",

        "Python libraries like Gensim"

      ],

      "metadata": {

        "id": "-kK3Axe9beVe"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "Topic modeling is a natural language processing (NLP) technique used to uncover hidden topics or themes within a collection of documents. It is a way to extract meaningful information from unstructured text data by identifying patterns and relationships among words and documents.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "\n",

        "The goal of topic modeling is to automatically discover the main topics or themes that are present in a large corpus of text. It allows us to gain insights into the underlying structure of the text data and understand the different subjects or concepts that the documents cover.\n",

        "\n",

        "---\n",

        "Topic modeling can be applied in various domains and has numerous applications. Some examples include:\n",

        "\n",

        "1. Document clustering: Grouping similar documents together based on their topics.\n",

        "2. Document summarization: Identifying the most representative topics in a document collection to create concise summaries.\n",

        "3. Information retrieval: Enhancing search engines by indexing documents based on their topics rather than just keywords.\n",

        "4. Social media analysis: Analyzing trends and discussions on social media platforms by identifying the dominant topics.\n",

        "5. Market research: Understanding customer opinions and feedback by extracting topics from customer reviews or surveys.\n",

        "\n"

      ],

      "metadata": {

        "id": "mN_vWcLKb0ES"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "Latent Dirichlet Allocation (LDA):\n",

        "\n",

        "- LDA is a generative probabilistic model used for topic modeling.\n",

        "- It assumes that each document in a collection is a mixture of various topics, and each word in the document is attributable to one of the topics.\n",

        "- LDA infers the underlying topics by analyzing the co-occurrence patterns of words across multiple documents.\n",

        "- It models the distribution of topics in the corpus and the distribution of words within each topic.\n",

        "- LDA treats **topics as probability distributions over words** and **documents as probability distributions over topics**.\n",

        "- The algorithm iteratively updates the topic assignments for words and estimates the topic-word and document-topic distributions.\n",

        "- By analyzing these distributions, LDA can identify the main topics present in a collection of documents."

      ],

      "metadata": {

        "id": "ulBlDmN7ciAE"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "Non-Negative Matrix Factorization (NMF):\n",

        "\n",

        "- NMF is a matrix factorization technique commonly used for topic modeling.\n",

        "- It represents a document-term matrix as the product of two non-negative matrices: a document-topic matrix and a topic-term matrix.\n",

        "- NMF assumes that documents can be expressed as combinations of a fixed number of latent topics, and the topics can be represented by a fixed set of terms.\n",

        "- The algorithm iteratively updates the topic assignments for documents and the term assignments for topics, aiming to minimize the reconstruction error between the original matrix and the factorized representation.\n",

        "- NMF enforces non-negativity constraints, meaning that all the values in the matrices are non-negative, which helps in interpretability.\n",

        "- The resulting **document-topic matrix** and **topic-term matrix** can be used to identify the prominent topics and their associated terms."

      ],

      "metadata": {

        "id": "biE4BuSocrhG"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "Latent Dirichlet Allocation Video Lecture\n",

        "\n",

        "https://www.youtube.com/watch?v=T05t-SqKArY"

      ],

      "metadata": {

        "id": "b3g2SVqiPkpz"

      }

    },

    {

      "cell_type": "markdown",

      "source": [

        "## Hands-on Exercise: Implementing a Topic Modeling Algorithm (e.g., LDA) using Python Libraries like Gensim\n",

        "\n",

       "---\n",

        "\n",

        "\n",

        "In this hands-on exercise, we will learn how to implement a topic modeling algorithm, such as Latent Dirichlet Allocation (LDA), using Python libraries like Gensim. Topic modeling is a powerful technique for discovering hidden themes or topics in a collection of documents. We will walk through the steps involved in preprocessing the text data, training an LDA model, and analyzing the results.\n",

        "\n",

        "---\n",

        "\n",

        "\n",

        "\n",

        "Note: Before proceeding with this exercise, make sure you have Gensim and other necessary libraries installed. You can install Gensim using pip install gensim."

      ],

      "metadata": {

        "id": "OH0rB7S8qsFx"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "!pip install gensim"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "ZN4Z6Y4paeKW",

        "outputId": "d4fb1634-5ae7-45d8-9d9e-251c356335cc"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",

            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",

            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.24.3)\n",

            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",

            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"

          ]

        }

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "# Exercise 1: Preprocessing the Text Data\n",

        "In this exercise, we will perform preprocessing on the text data to prepare it for topic modeling.\n",

        "\n",

        "# Task:\n",

        "\n",

        "*   Load a collection of documents.\n",

        "*   Preprocess the text data by performing the following steps:\n",

        "*   Convert the text to lowercase.\n",

        "*   Tokenize the text into individual words.\n",

        "*   Convert the text to lowercase.\n",

        "*   Remove stopwords and punctuation.\n",

        "*   Perform stemming or lemmatization to reduce words to their base forms."

      ],

      "metadata": {

        "id": "mRJerXJtrVFG"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "import nltk\n",

        "nltk.download('punkt')\n",

        "nltk.download('stopwords')\n",

        "nltk.download('wordnet')"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "GAIV3Ivrs2P8",

        "outputId": "141d6bf3-6b4d-4692-93bd-82660781e5e1"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",

            "[nltk_data]   Package punkt is already up-to-date!\n",

            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",

            "[nltk_data]   Package stopwords is already up-to-date!\n",

            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",

            "[nltk_data]   Package wordnet is already up-to-date!\n"

          ]

        },

        {

          "output_type": "execute_result",

          "data": {

            "text/plain": [

              "True"

            ]

          },

          "metadata": {},

          "execution_count": 2

        }

      ]

    },

    {

      "cell_type": "code",

      "source": [

        "from nltk.tokenize import word_tokenize\n",

        "from nltk.corpus import stopwords\n",

        "from nltk.stem import PorterStemmer\n",

        "from nltk.stem.wordnet import WordNetLemmatizer\n",

        "import string\n",

        "# Load documents\n",

        "\n",

        "documents = [\n",

        "    \"Cricket is a good sport. I like football also. What do you like to play?\",\n",

        "    \"Science is about experimenting and discovering laws of nature. Physics, Chemistry and Biology are fundamental sciences.\",\n",

        "    \"Which is a better sport, cricket or football?\"\n",

        "]\n",

        "\n",

        "# Preprocess the text data\n",

        "def preprocess_text(text):\n",

        "    # Convert to lowercase\n",

        "    text = text.lower()\n",

        "\n",

        "    # Tokenize the text\n",

        "    tokens = word_tokenize(text)\n",

        "\n",

        "    # Remove stopwords and punctuation\n",

        "    stop_words = set(stopwords.words('english'))\n",

        "    punctuation = set(string.punctuation)\n",

        "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",

        "\n",

        "    # Perform lemmatization or stemming\n",

        "    lemmatizer = WordNetLemmatizer()\n",

        "    stemmer = PorterStemmer()\n",

        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",

        "    #tokens = [stemmer.stem(word) for word in tokens]  # Uncomment this line for stemming\n",

        "\n",

        "    return tokens\n",

        "\n",

        "# Apply preprocessing to all documents\n",

        "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",

        "\n",

        "# Print the preprocessed documents\n",

        "for i, doc in enumerate(preprocessed_documents):\n",

        "    print(f\"Document {i+1}: {doc}\")\n"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "07sG2YQOsnLN",

        "outputId": "5943a214-d189-4da1-b170-6a77813d3b48"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Document 1: ['cricket', 'good', 'sport', 'like', 'football', 'also', 'like', 'play']\n",

            "Document 2: ['science', 'experimenting', 'discovering', 'law', 'nature', 'physic', 'chemistry', 'biology', 'fundamental', 'science']\n",

            "Document 3: ['better', 'sport', 'cricket', 'football']\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",

            "  and should_run_async(code)\n"

          ]

        }

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "## Exercise 2: Training an LDA Model\n",

        "In this exercise, we will train an LDA model on the preprocessed text data.\n",

        "\n",

        "Task:\n",

        "\n",

        "\n",

        "*   Convert the preprocessed text data into a bag-of-words representation.\n",

        "*   Train an LDA model on the bag-of-words representation with the desired number of topics.\n",

        "\n",

        "\n",

        "\n"

      ],

      "metadata": {

        "id": "MCotcpi_yTh8"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "from gensim import corpora\n",

        "from gensim.models import LdaModel\n",

        "\n",

        "# Create a dictionary from the preprocessed documents\n",

        "dictionary = corpora.Dictionary(preprocessed_documents)\n",

        "\n",

        "# Create a bag-of-words representation of the documents\n",

        "bow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]\n",

        "\n",

        "# Train the LDA model\n",

        "num_topics = 2\n",

        "lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",

        "\n",

        "# Print the topics\n",

        "topics = lda_model.print_topics(num_topics=num_topics)\n",

        "for topic in topics:\n",

        "    print(topic)\n"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "P2KCEn8Cz6G4",

        "outputId": "c3dd819f-7f9d-4c2f-f212-a134c32edc22"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "(0, '0.135*\"science\" + 0.081*\"discovering\" + 0.081*\"law\" + 0.081*\"biology\" + 0.081*\"physic\" + 0.081*\"chemistry\" + 0.081*\"nature\" + 0.081*\"experimenting\" + 0.081*\"fundamental\" + 0.027*\"better\"')\n",

            "(1, '0.122*\"like\" + 0.122*\"football\" + 0.122*\"cricket\" + 0.122*\"sport\" + 0.073*\"also\" + 0.073*\"play\" + 0.073*\"good\" + 0.073*\"better\" + 0.025*\"science\" + 0.025*\"fundamental\"')\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",

            "  and should_run_async(code)\n"

          ]

        }

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "# Exercise 3: Analyzing the Results\n",

        "In this exercise, we will analyze the results of the trained LDA model.\n",

        "\n",

        "Task:\n",

        "\n",

        "*   Print the most representative document for each topic.\n",

        "*   Visualize the topics using the pyLDAvis library.\n"

      ],

      "metadata": {

        "id": "AR5vn_mc0DZV"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "!pip install pyLDAvis"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "XVQLcmmu1aHh",

        "outputId": "d836dac6-6761-4275-a02d-fcd6dd8d27d8"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",

            "  and should_run_async(code)\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",

            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",

            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.24.3)\n",

            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.10.1)\n",

            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.2)\n",

            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.0)\n",

            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",

            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.4)\n",

            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",

            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",

            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.1)\n",

            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",

            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",

            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",

            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",

            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",

            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",

            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",

            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n"

          ]

        }

      ]

    },

    {

      "cell_type": "code",

      "source": [

        "import pyLDAvis.gensim\n",

        "\n",

        "# Print the most representative document for each topic\n",

        "for i in range(num_topics):\n",

        "    topic_documents = lda_model.get_document_topics(bow_corpus)\n",

        "    print(topic_documents)\n",

        "    sorted_documents = sorted(topic_documents, key=lambda x: x[i][1], reverse=True)\n",

        "    most_representative_doc = sorted_documents[0]\n",

        "    print(f\"Topic {i+1}: Document {most_representative_doc[0]} - Probability: {most_representative_doc[1][0]}\")\n",

        "\n",

        "# Visualize the topics\n",

        "lda_visualization = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",

        "pyLDAvis.display(lda_visualization)\n"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/",

          "height": 986

        },

        "id": "vA0xcGaa0NUp",

        "outputId": "979566d2-d5d5-45e8-f2be-a957d6889ba1"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",

            "  and should_run_async(code)\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "<gensim.interfaces.TransformedCorpus object at 0x7fced5a753c0>\n",

            "Topic 1: Document (0, 0.95298934) - Probability: 1\n",

            "<gensim.interfaces.TransformedCorpus object at 0x7fced5a74850>\n",

            "Topic 2: Document (0, 0.05736766) - Probability: 1\n"

          ]

        },

        {

          "output_type": "execute_result",

          "data": {

            "text/plain": [

              "<IPython.core.display.HTML object>"

            ],

            "text/html": [

              "\n",

              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",

              "\n",

              "\n",

              "<div id=\"ldavis_el51471405263129192643651128817\" style=\"background-color:white;\"></div>\n",

              "<script type=\"text/javascript\">\n",

              "\n",

              "var ldavis_el51471405263129192643651128817_data = {\"mdsDat\": {\"x\": [0.08531424682503681, -0.08531424682503681], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [52.7237381448762, 47.2762618551238]}, \"tinfo\": {\"Term\": [\"science\", \"like\", \"football\", \"cricket\", \"sport\", \"discovering\", \"law\", \"biology\", \"physic\", \"chemistry\", \"nature\", \"experimenting\", \"fundamental\", \"also\", \"play\", \"good\", \"better\", \"like\", \"football\", \"cricket\", \"sport\", \"also\", \"play\", \"good\", \"better\", \"fundamental\", \"experimenting\", \"nature\", \"chemistry\", \"physic\", \"biology\", \"law\", \"discovering\", \"science\", \"science\", \"discovering\", \"law\", \"biology\", \"physic\", \"chemistry\", \"nature\", \"experimenting\", \"fundamental\", \"better\", \"good\", \"play\", \"also\", \"sport\", \"cricket\", \"football\", \"like\"], \"Freq\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4132110261648974, 1.4119841080156643, 1.4119041686419909, 1.4116070534347598, 0.8475346102946332, 0.8473310889703081, 0.847267569576092, 0.8452549121993584, 0.28491989404129425, 0.28488755100281077, 0.28476059863532305, 0.28473767547979134, 0.2847124405639939, 0.284711619565021, 0.28464987180016743, 0.2845938062124154, 0.2851550670365468, 1.4021133900621354, 0.841035775510238, 0.8409802138647389, 0.8409190728071394, 0.8409182203969574, 0.8408931905343406, 0.840870407934931, 0.8407445611953346, 0.840712402083923, 0.2850288585366493, 0.2830328432307143, 0.28296991986091613, 0.2827680923773701, 0.2850123140299351, 0.2847177675661384, 0.28463839655441947, 0.28342167788441486], \"Total\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.6966327040493123, 1.6966225045700838, 1.6966219362081292, 1.6966193674646948, 1.1303027026720032, 1.1303010088312242, 1.1303004128068062, 1.1302837707360078, 1.1256322961252172, 1.1256321121981454, 1.125631006570254, 1.125630866014132, 1.1256306609609514, 1.1256306923721604, 1.1256300856649064, 1.1256295817226534, 1.6872684570986822, 1.6872684570986822, 1.1256295817226534, 1.1256300856649064, 1.1256306923721604, 1.1256306609609514, 1.125630866014132, 1.125631006570254, 1.1256321121981454, 1.1256322961252172, 1.1302837707360078, 1.1303004128068062, 1.1303010088312242, 1.1303027026720032, 1.6966193674646948, 1.6966219362081292, 1.6966225045700838, 1.6966327040493123], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.1051, -2.1059, -2.106, -2.1062, -2.6164, -2.6166, -2.6167, -2.6191, -3.7065, -3.7066, -3.707, -3.7071, -3.7072, -3.7072, -3.7074, -3.7076, -3.7057, -2.0039, -2.515, -2.5151, -2.5151, -2.5151, -2.5152, -2.5152, -2.5153, -2.5154, -3.597, -3.6041, -3.6043, -3.605, -3.5971, -3.5981, -3.5984, -3.6027], \"loglift\": [17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4573, 0.4565, 0.4564, 0.4562, 0.3522, 0.352, 0.3519, 0.3495, -0.7338, -0.7339, -0.7343, -0.7344, -0.7345, -0.7345, -0.7347, -0.7349, -1.1377, 0.564, 0.4577, 0.4576, 0.4576, 0.4576, 0.4575, 0.4575, 0.4573, 0.4573, -0.6285, -0.6355, -0.6357, -0.6365, -1.0347, -1.0357, -1.036, -1.0403]}, \"token.table\": {\"Topic\": [1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1], \"Freq\": [0.8847187551051844, 0.8847335738960749, 0.8883908432636947, 0.8883907062188229, 0.5894065016246066, 0.8883917198316776, 0.888389722684075, 0.589406304175716, 0.8883895775221772, 0.8847205474487627, 0.8883913221005486, 0.5894027609000605, 0.8883905952865976, 0.8883908680546242, 0.8847200809225495, 0.5926739137407543, 0.589407394007489], \"Term\": [\"also\", \"better\", \"biology\", \"chemistry\", \"cricket\", \"discovering\", \"experimenting\", \"football\", \"fundamental\", \"good\", \"law\", \"like\", \"nature\", \"physic\", \"play\", \"science\", \"sport\"]}, \"R\": 17, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",

              "\n",

              "function LDAvis_load_lib(url, callback){\n",

              "  var s = document.createElement('script');\n",

              "  s.src = url;\n",

              "  s.async = true;\n",

              "  s.onreadystatechange = s.onload = callback;\n",

              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",

              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",

              "}\n",

              "\n",

              "if(typeof(LDAvis) !== \"undefined\"){\n",

              "   // already loaded: just create the visualization\n",

              "   !function(LDAvis){\n",

              "       new LDAvis(\"#\" + \"ldavis_el51471405263129192643651128817\", ldavis_el51471405263129192643651128817_data);\n",

              "   }(LDAvis);\n",

              "}else if(typeof define === \"function\" && define.amd){\n",

              "   // require.js is available: use it to load d3/LDAvis\n",

              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",

              "   require([\"d3\"], function(d3){\n",

              "      window.d3 = d3;\n",

              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",

              "        new LDAvis(\"#\" + \"ldavis_el51471405263129192643651128817\", ldavis_el51471405263129192643651128817_data);\n",

              "      });\n",

              "    });\n",

              "}else{\n",

              "    // require.js not available: dynamically load d3 & LDAvis\n",

              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",

              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",

              "                 new LDAvis(\"#\" + \"ldavis_el51471405263129192643651128817\", ldavis_el51471405263129192643651128817_data);\n",

              "            })\n",

              "         });\n",

              "}\n",

              "</script>"

            ]

          },

          "metadata": {},

          "execution_count": 27

        }

      ]

    },

    {

      "cell_type": "markdown",

      "source": [

        "### Exercise: Print the topic distribution for each of the 4 documents"

      ],

      "metadata": {

        "id": "ZBEYz_xwrDz3"

      }

    },

    {

      "cell_type": "code",

      "source": [

        "for doc_id, topic_distribution in enumerate(topic_documents):\n",

        "        print(f\"Document ID: {doc_id}\")\n",

        "\n",

        "        if isinstance(topic_distribution, int):\n",

        "            print(\"No topics found for this document.\")\n",

        "        else:\n",

        "            for topic, probability in topic_distribution:\n",

        "                print(f\"Topic {topic}: Probability {probability}\")\n",

        "\n",

        "        print()  # Print an empty line to separate documents\n"

      ],

      "metadata": {

        "colab": {

          "base_uri": "https://localhost:8080/"

        },

        "id": "nFMUX8GbsOA1",

        "outputId": "6a04fa5d-eb3b-46c0-e71b-66bf7a97b478"

      },

      "execution_count": null,

      "outputs": [

        {

          "output_type": "stream",

          "name": "stdout",

          "text": [

            "Document ID: 0\n",

            "Topic 0: Probability 0.05736686661839485\n",

            "Topic 1: Probability 0.9426330924034119\n",

            "\n",

            "Document ID: 1\n",

            "Topic 0: Probability 0.9529885649681091\n",

            "Topic 1: Probability 0.047011446207761765\n",

            "\n",

            "Document ID: 2\n",

            "Topic 0: Probability 0.1029861643910408\n",

            "Topic 1: Probability 0.8970138430595398\n",

            "\n"

          ]

        },

        {

          "output_type": "stream",

          "name": "stderr",

          "text": [

            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",

            "  and should_run_async(code)\n"

          ]

        }

      ]

    },

    {

      "cell_type": "code",

      "source": [

        "# From above it is clear that 1st and 3rd Documents are about the same Topic (Sports), wheras the 2nd Document is about a different topic (Science)"

      ],

      "metadata": {

        "id": "ZFgcuWAPuzgP"

      },

      "execution_count": null,

      "outputs": []

    }

  ]

}

 

